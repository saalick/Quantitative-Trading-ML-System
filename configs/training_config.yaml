training:
  batch_size: 32
  epochs: 50
  learning_rate: 0.001
  optimizer: "SGD"
  momentum: 0.9
  weight_decay: 0.0001
  early_stopping_patience: 10
  grad_clip: 1.0

data:
  sequence_length: 60
  train_split: 0.7
  val_split: 0.15
  test_split: 0.15
